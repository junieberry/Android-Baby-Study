{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_GRU_Surname.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYyzGOsBGG1U3RJQmYIlf9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30981757c4a74755b7a0beaca32a5aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_23b7ae4120e144dd85b3324e8aeaf31b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eb8703fe478d41218d5f98a0bb77f2be",
              "IPY_MODEL_90a8eb7a8b934a2d852e91f3f0a18f44",
              "IPY_MODEL_72913cd2c02947ffb61e1b1cfc356fd5"
            ]
          }
        },
        "23b7ae4120e144dd85b3324e8aeaf31b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb8703fe478d41218d5f98a0bb77f2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b52ada70cbc6466f9b366969bbc22896",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "training routine: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a05ab9d95aaf433e9dab1f56937e982e"
          }
        },
        "90a8eb7a8b934a2d852e91f3f0a18f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8659013f61c0486eb6f6f673addf3e1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21b2d91c704645249781cf1feeca9028"
          }
        },
        "72913cd2c02947ffb61e1b1cfc356fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e22ab6e6f9284e0a9caee14e0e8279dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [05:45&lt;00:00,  3.39s/it, sample1=Czech-&gt;Uvy, sample2=Russian-&gt;Vavsoterska]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c50279e601cb47f7bb5e136394a46535"
          }
        },
        "b52ada70cbc6466f9b366969bbc22896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a05ab9d95aaf433e9dab1f56937e982e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8659013f61c0486eb6f6f673addf3e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21b2d91c704645249781cf1feeca9028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e22ab6e6f9284e0a9caee14e0e8279dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c50279e601cb47f7bb5e136394a46535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72ca7cdd0cdd40bda59eb866359e5dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cc60040f727b4b3198dcf594a76ea502",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a7ec0e887bb4d558e7facf2c1b72185",
              "IPY_MODEL_ea81744fa6684b539c42adae4b16616e",
              "IPY_MODEL_9464c094ec894c4bb6fe079148b1bc32"
            ]
          }
        },
        "cc60040f727b4b3198dcf594a76ea502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a7ec0e887bb4d558e7facf2c1b72185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_328ade7c499c42258e29803976b98068",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=train:  98%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32762a2ab11644f2bf0430ee8565cf94"
          }
        },
        "ea81744fa6684b539c42adae4b16616e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab21f93a2ece42a19001df66223c66c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 60,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbb7df10405f42749bae31dc5d8de9c2"
          }
        },
        "9464c094ec894c4bb6fe079148b1bc32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f44896095004e3e801402bf8fa4179a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/60 [05:44&lt;00:02,  2.26s/it, acc=28.7, epoch=99, loss=2.42]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_059b431a1209490bbe0ab3d51f41e3c9"
          }
        },
        "328ade7c499c42258e29803976b98068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32762a2ab11644f2bf0430ee8565cf94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab21f93a2ece42a19001df66223c66c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbb7df10405f42749bae31dc5d8de9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f44896095004e3e801402bf8fa4179a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "059b431a1209490bbe0ab3d51f41e3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6feadd74341418eabe1835eb0805080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f71dc56d651747c2b0099f58738158ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_54ffc33b1f0d4574bf0ee9ec4e37e37b",
              "IPY_MODEL_838bd663f8ed4c69b4791a466b160791",
              "IPY_MODEL_3cc9a4269bb44a628927baff001f3d10"
            ]
          }
        },
        "f71dc56d651747c2b0099f58738158ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54ffc33b1f0d4574bf0ee9ec4e37e37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_496ea69275eb4b2baf8fb3991e7fc614",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=val:  92%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd293671f5524706abeaab8f33e5b3f4"
          }
        },
        "838bd663f8ed4c69b4791a466b160791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eef3b330321e4272a1584f4ee275ce52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 12,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65d97d6d368d40de9610036db53456b8"
          }
        },
        "3cc9a4269bb44a628927baff001f3d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca532a0e757e4523ac939b21bc730d0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11/12 [05:45&lt;00:03,  3.49s/it, acc=28.1, epoch=99, loss=2.45]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eff18abbe14b4d319290c056381baacb"
          }
        },
        "496ea69275eb4b2baf8fb3991e7fc614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd293671f5524706abeaab8f33e5b3f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eef3b330321e4272a1584f4ee275ce52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65d97d6d368d40de9610036db53456b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca532a0e757e4523ac939b21bc730d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eff18abbe14b4d319290c056381baacb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junieberry/Android-Baby-Study/blob/main/07_GRU_Surname/07_GRU_Surname.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peXjMe0m9lMY"
      },
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCmljpPq7OL5"
      },
      "source": [
        "# 7.3 문자 RNN으로 성씨 생성하기\n",
        "\n",
        "각 타임 스텝에서 RNN이 성씨에 포함될 수 있는 문자 집합에 대한 확률 분포를 계산\n",
        "\n",
        "\n",
        "1. 조건이 없는 SurnamgeGenerationModel\n",
        "\n",
        "  국적 정보를 사용하지 않고 성씨 문자의 시퀀스를 예측\n",
        "\n",
        "2. 조건이 있는 SurnameGenerationModel\n",
        "\n",
        "  초기 은닉 상태에 임베딩된 특정 국적을 활용해서 시퀀스 예\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuDjd79X9lvw"
      },
      "source": [
        "### 7.3.1 SurnamgeDataset 클래스\n",
        "\n",
        "- 판다스 데이터프레임을 사용해 데이터셋과 SurnameDataset 객체를 로드\n",
        "- SurnamgeVectorizer은 토큰-정수 매핑\n",
        "- 이때 `SurnamgeDatase.__getitem__()`메서드는 예측 타깃에 대한 정수 시퀀스 출력\n",
        "- 이 메서드는 `from_vector`과 `to_vector` 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZqQGQMD9koa"
      },
      "source": [
        "\n",
        "class SurnameDataset(Dataset):\n",
        "    def __init__(self, surname_df, vectorizer):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            surname_df (pandas.DataFrame): 데이터셋\n",
        "            vectorizer (SurnameVectorizer): 데이터셋에서 만든 Vectorizer 객체\n",
        "        \"\"\"\n",
        "        self.surname_df = surname_df \n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        self._max_seq_length = max(map(len, self.surname_df.surname)) + 2\n",
        "\n",
        "        self.train_df = self.surname_df[self.surname_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.surname_df[self.surname_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.surname_df[self.surname_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
        "                             'val': (self.val_df, self.validation_size), \n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, surname_csv):\n",
        "        \"\"\"데이터셋을 로드하고 새로운 Vectorizer를 만듭니다\n",
        "        \n",
        "        매개변수:\n",
        "            surname_csv (str): 데이터셋의 위치\n",
        "        반환값:\n",
        "            SurnameDataset 객체\n",
        "        \"\"\"        \n",
        "        surname_df = pd.read_csv(surname_csv)\n",
        "        return cls(surname_df, SurnameVectorizer.from_dataframe(surname_df))\n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, surname_csv, vectorizer_filepath):\n",
        "        \"\"\"데이터셋과 새로운 Vectorizer 객체를 로드합니다.\n",
        "        캐시된 Vectorizer 객체를 재사용할 때 사용합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            surname_csv (str): 데이터셋의 위치\n",
        "            vectorizer_filepath (str): Vectorizer 객체의 저장 위치\n",
        "        반환값:\n",
        "            SurnameDataset의 인스턴스\n",
        "        \"\"\"\n",
        "        surname_df = pd.read_csv(surname_csv)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(surname_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"파일에서 Vectorizer 객체를 로드하는 정적 메서드\n",
        "        \n",
        "        매개변수:\n",
        "            vectorizer_filepath (str): 직렬화된 Vectorizer 객체의 위치\n",
        "        반환값:\n",
        "            SurnameVectorizer의 인스턴스\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"Vectorizer 객체를 json 형태로 디스크에 저장합니다\n",
        "        \n",
        "        매개변수:\n",
        "            vectorizer_filepath (str): Vectorizer 객체의 저장 위치\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" 벡터 변환 객체를 반환합니다 \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "     ##################################################################\n",
        "\n",
        "     ## 예측 타깃에 대한 정수 시퀀스 출력\n",
        "     ## 예측 타깃에 대한 정수 시퀀스 출력\n",
        "     ## vectorize 메서드로 입력으로 사용되는 정수 시퀀스와 출력으로 사용되는 정수 시퀀스를 계산\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"파이토치 데이터셋의 주요 진입 메서드\n",
        "        \n",
        "        매개변수:\n",
        "            index (int): 데이터 포인트에 대한 인덱스 \n",
        "        반환값:\n",
        "            데이터 포인트(x_data, y_target, class_index)를 담고 있는 딕셔너리\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "        \n",
        "        from_vector, to_vector = \\\n",
        "            self._vectorizer.vectorize(row.surname, self._max_seq_length)\n",
        "        \n",
        "        nationality_index = \\\n",
        "            self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
        "\n",
        "        return {'x_data': from_vector, \n",
        "                'y_target': to_vector, \n",
        "                'class_index': nationality_index}\n",
        "        \n",
        "        \n",
        "     ##################################################################\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환합니다\n",
        "        \n",
        "        매개변수:\n",
        "            batch_size (int)\n",
        "        반환값:\n",
        "            배치 개수\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n",
        "    \n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"): \n",
        "    \"\"\"\n",
        "    파이토치 DataLoader를 감싸고 있는 제너레이터 함수.\n",
        "    걱 텐서를 지정된 장치로 이동합니다.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPKIvNFhDIzM"
      },
      "source": [
        "### 7.3.2 벡터 변환 클래스\n",
        "\n",
        "- SequenceVocabulary >> 개별 토큰 정수로 매핑\n",
        "- SurnameVectorizer >> 정수 매핑 관리\n",
        "- DataLoader >> SurnameVectorizer의 결과를 미니배치로\n",
        "\n",
        "**SurnameVectorizer와 END-OF-Sequence**\n",
        "\n",
        "\n",
        "타임 스텝마다 토큰 샘플과 토큰 타깃을 표현하는 정수 시퀀스 2개를 기대\n",
        "\n",
        "```\n",
        "예제의 성씨와 같이 훈련 시퀀스가 예측 대상이 됨\n",
        "\n",
        "하나의 토큰 시퀀스에서 토큰을 하나씩 엇갈리게 하는 식으로 샘플과 타깃 구성.. 진짜 무슨 말이지\n",
        "\n",
        "아 이해햇음\n",
        "\n",
        "0 1 2 3 끝\n",
        "\n",
        "시작 0 1 2 3\n",
        "\n",
        "요렇게\n",
        "```\n",
        "1. SequenceVocabulary로 각 토큰을 적절한 인덱스로 매핑\n",
        "2. 시퀀스 시작과 시퀀스 끝에 `BEGIN-OF-SEQUNCE`와 `END-OF-SEQUENCE` 토큰 추가\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9xdN2pGQkei"
      },
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스 \"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            token_to_idx (dict): 기존 토큰-인덱스 매핑 딕셔너리\n",
        "        \"\"\"\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "    def to_serializable(self):\n",
        "        \"\"\" 직렬화할 수 있는 딕셔너리를 반환합니다 \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" 직렬화된 딕셔너리에서 Vocabulary 객체를 만듭니다 \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\" 토큰을 기반으로 매핑 딕셔너리를 업데이트합니다\n",
        "\n",
        "        매개변수:\n",
        "            token (str): Vocabulary에 추가할 토큰\n",
        "        반환값:\n",
        "            index (int): 토큰에 상응하는 정수\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "            \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"토큰 리스트를 Vocabulary에 추가합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            tokens (list): 문자열 토큰 리스트\n",
        "        반환값:\n",
        "            indices (list): 토큰 리스트에 상응되는 인덱스 리스트\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"토큰에 대응하는 인덱스를 추출합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            token (str): 찾을 토큰 \n",
        "        반환값:\n",
        "            index (int): 토큰에 해당하는 인덱스\n",
        "        \"\"\"\n",
        "        return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\" 인덱스에 해당하는 토큰을 반환합니다.\n",
        "        \n",
        "        매개변수: \n",
        "            index (int): 찾을 인덱스\n",
        "        반환값:\n",
        "            token (str): 인텍스에 해당하는 토큰\n",
        "        에러:\n",
        "            KeyError: 인덱스가 Vocabulary에 없을 때 발생합니다.\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1jGLR-sQmd8"
      },
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "        self._mask_token = mask_token\n",
        "        self._unk_token = unk_token\n",
        "        self._begin_seq_token = begin_seq_token\n",
        "        self._end_seq_token = end_seq_token\n",
        "\n",
        "        self.mask_index = self.add_token(self._mask_token)\n",
        "        self.unk_index = self.add_token(self._unk_token)\n",
        "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
        "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\n",
        "        contents.update({'unk_token': self._unk_token,\n",
        "                         'mask_token': self._mask_token,\n",
        "                         'begin_seq_token': self._begin_seq_token,\n",
        "                         'end_seq_token': self._end_seq_token})\n",
        "        return contents\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\" 토큰에 대응하는 인덱스를 추출합니다.\n",
        "        토큰이 없으면 UNK 인덱스를 반환합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            token (str): 찾을 토큰 \n",
        "        반환값:\n",
        "            index (int): 토큰에 해당하는 인덱스\n",
        "        노트:\n",
        "            UNK 토큰을 사용하려면 (Vocabulary에 추가하기 위해)\n",
        "            `unk_index`가 0보다 커야 합니다.\n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XlnrDilQurR"
      },
      "source": [
        "\n",
        "class SurnameVectorizer(object):\n",
        "    \"\"\" 어휘 사전을 생성하고 관리합니다 \"\"\"\n",
        "    def __init__(self, char_vocab, nationality_vocab):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            char_vocab (Vocabulary): 문자를 정수로 매핑합니다\n",
        "            nationality_vocab (Vocabulary): 국적을 정수로 매핑합니다\n",
        "        \"\"\"\n",
        "        self.char_vocab = char_vocab\n",
        "        self.nationality_vocab = nationality_vocab\n",
        "\n",
        "##############################################################################################\n",
        "\n",
        "    def vectorize(self, surname, vector_length=-1):\n",
        "        \"\"\" 성씨를 샘플과 타깃 벡터로 변환합니다\n",
        "        성씨 벡터를 두 개의 벡터 surname[:-1]와 surname[1:]로 나누어 출력합니다.\n",
        "        각 타임스텝에서 첫 번째 벡터가 샘플이고 두 번째 벡터가 타깃입니다.\n",
        "        \n",
        "        매개변수:\n",
        "            surname (str): 벡터로 변경할 성씨\n",
        "            vector_length (int): 인덱스 벡터의 길이를 맞추기 위한 매개변수\n",
        "        반환값:\n",
        "            튜플: (from_vector, to_vector)\n",
        "                from_vector (numpy.ndarray): 샘플 벡터 \n",
        "                to_vector (numpy.ndarray): 타깃 벡터 vector\n",
        "        \"\"\"\n",
        "\n",
        "        ## 성씨 이름을 정수로 매핑하고 앞 뒤에 토큰을 더해줌\n",
        "        indices = [self.char_vocab.begin_seq_index] \n",
        "        indices.extend(self.char_vocab.lookup_token(token) for token in surname)\n",
        "        indices.append(self.char_vocab.end_seq_index)\n",
        "\n",
        "        if vector_length < 0:\n",
        "            vector_length = len(indices) - 1\n",
        "\n",
        "        ## from_vector 만들어주기\n",
        "        from_vector = np.empty(vector_length, dtype=np.int64)         \n",
        "        from_indices = indices[:-1]\n",
        "        from_vector[:len(from_indices)] = from_indices\n",
        "        # mask index로 패딩\n",
        "        from_vector[len(from_indices):] = self.char_vocab.mask_index\n",
        "\n",
        "        ## to_vector 만들어주기\n",
        "        to_vector = np.empty(vector_length, dtype=np.int64)\n",
        "        to_indices = indices[1:]\n",
        "        to_vector[:len(to_indices)] = to_indices\n",
        "        #mask index로 패딩\n",
        "        to_vector[len(to_indices):] = self.char_vocab.mask_index\n",
        "        \n",
        "        return from_vector, to_vector\n",
        "\n",
        "\n",
        "##############################################################################################\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, surname_df):\n",
        "        \"\"\"데이터셋 데이터프레임으로 객체를 초기화합니다\n",
        "        \n",
        "        매개변수:\n",
        "            surname_df (pandas.DataFrame): 성씨 데이터셋\n",
        "        반환값:\n",
        "            SurnameVectorizer 객체\n",
        "        \"\"\"\n",
        "        char_vocab = SequenceVocabulary()\n",
        "        nationality_vocab = Vocabulary()\n",
        "\n",
        "        for index, row in surname_df.iterrows():\n",
        "            for char in row.surname:\n",
        "                char_vocab.add_token(char)\n",
        "            nationality_vocab.add_token(row.nationality)\n",
        "\n",
        "        return cls(char_vocab, nationality_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\"파일에서 SurnameVectorizer 객체를 초기화합니다\n",
        "        \n",
        "        매개변수:\n",
        "            contents (dict): SurnameVectorizer를 위해 두 개의 어휘 사전을 담은 딕셔너리\n",
        "                이 딕셔너리는 `vectorizer.to_serializable()`를 사용해 만듭니다\n",
        "        반환값:\n",
        "            SurnameVectorizer의 객체\n",
        "        \"\"\"\n",
        "        char_vocab = SequenceVocabulary.from_serializable(contents['char_vocab'])\n",
        "        nat_vocab =  Vocabulary.from_serializable(contents['nationality_vocab'])\n",
        "\n",
        "        return cls(char_vocab=char_vocab, nationality_vocab=nat_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        \"\"\" 직렬화된 결과를 반환합니다 \"\"\"\n",
        "        return {'char_vocab': self.char_vocab.to_serializable(), \n",
        "                'nationality_vocab': self.nationality_vocab.to_serializable()}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Dp6b6ZDVza"
      },
      "source": [
        "### 7.3.3 ElmanRNN을 GRU로 바꾸기\n",
        "\n",
        "LSTM이나 GRU로 바꾸는게 쉽다고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sslb8spyRvu4"
      },
      "source": [
        "### 7.3.4 모델 1 : 조건이 없는 SurnameGenerationModel\n",
        "\n",
        "성씨를 생성하기 전에 국적 정보를 사용하지 않는다.\n",
        "\n",
        "따라서 GRU가 편향되지 않은 계산을 수행\n",
        "\n",
        "**SurnameGenerationModel**\n",
        "\n",
        "- Embedding층, GRU층, Linear층 초기화\n",
        "- 정수를 3차원 텐서로 변환\n",
        "- 문자 인덱스 임베딩하여 GRU로 상태 계산\n",
        "- Linear 층을 사용해 토큰의 예측 확률 계산\n",
        "\n",
        "\n",
        "6장과의 가장 큰 차이는 상태 벡터의 처리다!\n",
        "- 6장에서는 배치 인덱스마다 하나의 벡터를 얻고 이를 기반으로 예측\n",
        "- 7장에서는 3차원 텐서를 2차원 텐서로 바꿔서 예측 벡터 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMUHkw9X61IM"
      },
      "source": [
        "# class SurnameGenerationModel(nn.Module):\n",
        "#     def __init__(self, char_embedding_size, char_vocab_size, rnn_hidden_size, \n",
        "#                  batch_first=True, padding_idx=0, dropout_p=0.5):\n",
        "#         \"\"\"\n",
        "#         매개변수:\n",
        "#             char_embedding_size (int): 문자 임베딩 크기\n",
        "#             char_vocab_size (int): 임베딩될 문자 개수\n",
        "#             rnn_hidden_size (int): RNN의 은닉 상태 크기\n",
        "#             batch_first (bool): 0번째 차원이 배치인지 시퀀스인지 나타내는 플래그\n",
        "#             padding_idx (int): 텐서 패딩을 위한 인덱스;\n",
        "#                 torch.nn.Embedding를 참고하세요\n",
        "#             dropout_p (float): 드롭아웃으로 활성화 출력을 0으로 만들 확률\n",
        "#         \"\"\"\n",
        "#         super(SurnameGenerationModel, self).__init__()\n",
        "        \n",
        "#         self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\n",
        "#                                      embedding_dim=char_embedding_size,\n",
        "#                                      padding_idx=padding_idx)\n",
        "\n",
        "#         self.rnn = nn.GRU(input_size=char_embedding_size, \n",
        "#                           hidden_size=rnn_hidden_size,\n",
        "#                           batch_first=batch_first)\n",
        "        \n",
        "#         self.fc = nn.Linear(in_features=rnn_hidden_size, \n",
        "#                             out_features=char_vocab_size)\n",
        "        \n",
        "#         self._dropout_p = dropout_p\n",
        "\n",
        "#     def forward(self, x_in, apply_softmax=False):\n",
        "#         \"\"\"모델의 정방향 계산\n",
        "        \n",
        "#         매개변수:\n",
        "#             x_in (torch.Tensor): 입력 데이터 텐서\n",
        "#                 x_in.shape는 (batch, input_dim)입니다.\n",
        "#             apply_softmax (bool): 소프트맥스 활성화를 위한 플래그로 훈련시에는 False가 되어야 합니다.\n",
        "#         반환값:\n",
        "#             결과 텐서. tensor.shape는 (batch, char_vocab_size)입니다.\n",
        "#         \"\"\"\n",
        "#         x_embedded = self.char_emb(x_in)\n",
        "\n",
        "#         y_out, _ = self.rnn(x_embedded)\n",
        "\n",
        "#         batch_size, seq_size, feat_size = y_out.shape\n",
        "#         y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
        "\n",
        "#         y_out = self.fc(F.dropout(y_out, p=self._dropout_p))\n",
        "                         \n",
        "#         if apply_softmax:\n",
        "#             y_out = F.softmax(y_out, dim=1)\n",
        "            \n",
        "#         new_feat_size = y_out.shape[-1]\n",
        "#         y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
        "            \n",
        "#         return y_out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXkGm58nVocj"
      },
      "source": [
        "### 7.3.5 모델2 : 조건이 있는 SurnameGenerationModel\n",
        "\n",
        "성씨 생성할때 국적을 고려\n",
        "\n",
        "은닉 상태 크기의 벡터로 국적을 임베딩하여 RNN의 초기 은닉 상태를 만든다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7z_RssIerqx"
      },
      "source": [
        "\n",
        "class SurnameGenerationModel(nn.Module):\n",
        "    def __init__(self, char_embedding_size, char_vocab_size, num_nationalities,\n",
        "                 rnn_hidden_size, batch_first=True, padding_idx=0, dropout_p=0.5):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            char_embedding_size (int): 문자 임베딩 크기\n",
        "            char_vocab_size (int): 임베딩될 문자 개수\n",
        "            rnn_hidden_size (int): RNN의 은닉 상태 크기\n",
        "            batch_first (bool): 0번째 차원이 배치인지 시퀀스인지 나타내는 플래그\n",
        "            padding_idx (int): 텐서 패딩을 위한 인덱스;\n",
        "                torch.nn.Embedding를 참고하세요\n",
        "            dropout_p (float): 드롭아웃으로 활성화 출력을 0으로 만들 확률\n",
        "        \"\"\"\n",
        "        super(SurnameGenerationModel, self).__init__()\n",
        "        \n",
        "        self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\n",
        "                                     embedding_dim=char_embedding_size,\n",
        "                                     padding_idx=padding_idx)\n",
        "        \n",
        "        \n",
        "        ####################################\n",
        "\n",
        "        ## nation embedding\n",
        "        \n",
        "        self.nation_emb = nn.Embedding(num_embeddings=num_nationalities,\n",
        "                                       embedding_dim=rnn_hidden_size)\n",
        "        \n",
        "\n",
        "        ####################################\n",
        "\n",
        "\n",
        "        self.rnn = nn.GRU(input_size=char_embedding_size, \n",
        "                          hidden_size=rnn_hidden_size,\n",
        "                          batch_first=batch_first)\n",
        "        \n",
        "        self.fc = nn.Linear(in_features=rnn_hidden_size, \n",
        "                            out_features=char_vocab_size)\n",
        "        \n",
        "        self._dropout_p = dropout_p\n",
        "\n",
        "    def forward(self, x_in, nationality_index, apply_softmax=False):\n",
        "        \"\"\"모델의 정방향 계산\n",
        "        \n",
        "        매개변수:\n",
        "            x_in (torch.Tensor): 입력 데이터 텐서\n",
        "                x_in.shape는 (batch, max_seq_size)입니다.\n",
        "            nationality_index (torch.Tensor): 각 데이터 포인트를 위한 국적 인덱스\n",
        "                RNN의 은닉 상태를 초기화하는데 사용합니다.\n",
        "            apply_softmax (bool): 소프트맥스 활성화를 위한 플래그로 훈련시에는 False가 되어야 합니다.\n",
        "        반환값:\n",
        "            결과 텐서. tensor.shape는 (batch, char_vocab_size)입니다.\n",
        "        \"\"\"\n",
        "        x_embedded = self.char_emb(x_in)\n",
        "        \n",
        "        \n",
        "        ####################################\n",
        "\n",
        "\n",
        "        # hidden_size: (num_layers * num_directions, batch_size, rnn_hidden_size)\n",
        "        nationality_embedded = self.nation_emb(nationality_index).unsqueeze(0)\n",
        "\n",
        "\n",
        "        ####################################\n",
        "\n",
        "        y_out, _ = self.rnn(x_embedded, nationality_embedded)\n",
        "\n",
        "        batch_size, seq_size, feat_size = y_out.shape\n",
        "        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
        "\n",
        "        y_out = self.fc(F.dropout(y_out, p=self._dropout_p))\n",
        "                         \n",
        "        if apply_softmax:\n",
        "            y_out = F.softmax(y_out, dim=1)\n",
        "\n",
        "        new_feat_size = y_out.shape[-1]\n",
        "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
        "            \n",
        "        return y_out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxCL1oG0fqXw",
        "outputId": "44cf5f30-8509-409a-a365-f490aa3a0ef0"
      },
      "source": [
        "a= [ 1, 2, 3, 4, 5]\n",
        "b = [0 for _ in a]\n",
        "b"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og9amUJQfJjk"
      },
      "source": [
        "## 타임 스텝마다 예측을 계산하고 다음 단계의 타임 스텝 입력으로 사용\n",
        "## 타임 스텝마다 소프트맥스 함수로 확률 분포로 변환하고\n",
        "## 인덱스 확률에 비례해서 인덱스 선택\n",
        "## 매번 다른 출력이 만들어짐\n",
        "\n",
        "def sample_from_model(model, vectorizer, nationalities, sample_size=20, \n",
        "                      temperature=1.0):\n",
        "    \"\"\"모델이 만든 인덱스 시퀀스를 샘플링합니다.\n",
        "    \n",
        "    매개변수:\n",
        "        model (SurnameGenerationModel): 훈련 모델\n",
        "        vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "        nationalities (list): 국적을 나타내는 정수 리스트\n",
        "        sample_size (int): 샘플의 최대 길이\n",
        "        temperature (float): 무작위성 정도\n",
        "            0.0 < temperature < 1.0 이면 최대 값을 선택할 가능성이 높습니다\n",
        "            temperature > 1.0 이면 균등 분포에 가깝습니다\n",
        "    반환값:\n",
        "        indices (torch.Tensor): 인덱스 행렬\n",
        "        shape = (num_samples, sample_size)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ## 국적 인덱스트를 임베딩으로 바꿔서 GRU의 초기 은닉 상태로 변환\n",
        "    \n",
        "    num_samples = len(nationalities)\n",
        "    begin_seq_index = [vectorizer.char_vocab.begin_seq_index \n",
        "                       for _ in range(num_samples)]\n",
        "    begin_seq_index = torch.tensor(begin_seq_index, \n",
        "                                   dtype=torch.int64).unsqueeze(dim=1)\n",
        "    indices = [begin_seq_index]\n",
        "    nationality_indices = torch.tensor(nationalities, dtype=torch.int64).unsqueeze(dim=0)\n",
        "    h_t = model.nation_emb(nationality_indices)\n",
        "    \n",
        "    for time_step in range(sample_size):\n",
        "        x_t = indices[time_step]\n",
        "        x_emb_t = model.char_emb(x_t)\n",
        "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n",
        "        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\n",
        "        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\n",
        "        indices.append(torch.multinomial(probability_vector, num_samples=1))\n",
        "    indices = torch.stack(indices).squeeze().permute(1, 0)\n",
        "    return indices\n",
        "\n",
        "def decode_samples(sampled_indices, vectorizer):\n",
        "    \"\"\"인덱스를 성씨 문자열로 변환합니다\n",
        "    \n",
        "    매개변수:\n",
        "        sampled_indices (torch.Tensor): `sample_from_model` 함수에서 얻은 인덱스\n",
        "        vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "    \"\"\"\n",
        "    decoded_surnames = []\n",
        "    vocab = vectorizer.char_vocab\n",
        "    \n",
        "    for sample_index in range(sampled_indices.shape[0]):\n",
        "        surname = \"\"\n",
        "        for time_step in range(sampled_indices.shape[1]):\n",
        "            sample_item = sampled_indices[sample_index, time_step].item()\n",
        "            if sample_item == vocab.begin_seq_index:\n",
        "                continue\n",
        "            elif sample_item == vocab.end_seq_index:\n",
        "                break\n",
        "            else:\n",
        "                surname += vocab.lookup_index(sample_item)\n",
        "        decoded_surnames.append(surname)\n",
        "    return decoded_surnames"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylEJOCFNhzex"
      },
      "source": [
        "### 헬퍼 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFXJ-1_BhyW2"
      },
      "source": [
        "\n",
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"훈련 상태를 업데이트합니다.\n",
        "\n",
        "    콤포넌트:\n",
        "     - 조기 종료: 과대 적합 방지\n",
        "     - 모델 체크포인트: 더 나은 모델을 저장합니다\n",
        "\n",
        "    :param args: 메인 매개변수\n",
        "    :param model: 훈련할 모델\n",
        "    :param train_state: 훈련 상태를 담은 딕셔너리\n",
        "    :returns:\n",
        "        새로운 훈련 상태\n",
        "    \"\"\"\n",
        "\n",
        "    # 적어도 한 번 모델을 저장합니다\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # 성능이 향상되면 모델을 저장합니다\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "         \n",
        "        # 손실이 나빠지면\n",
        "        if loss_t >= loss_tm1:\n",
        "            # 조기 종료 단계 업데이트\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # 손실이 감소하면\n",
        "        else:\n",
        "            # 최상의 모델 저장\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "                train_state['early_stopping_best_val'] = loss_t\n",
        "\n",
        "            # 조기 종료 단계 재설정\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # 조기 종료 여부 확인\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "########################################################\n",
        "\n",
        "\n",
        "def normalize_sizes(y_pred, y_true):\n",
        "    \"\"\"텐서 크기 정규화\n",
        "    \n",
        "    매개변수:\n",
        "        y_pred (torch.Tensor): 모델의 출력\n",
        "            3차원 텐서이면 행렬로 변환합니다.\n",
        "        y_true (torch.Tensor): 타깃 예측\n",
        "            행렬이면 벡터로 변환합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    ## 3차원이면 행렬로 변환\n",
        "    if len(y_pred.size()) == 3:\n",
        "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
        "    \n",
        "    ## 행렬이면 벡터로 변환\n",
        "    if len(y_true.size()) == 2:\n",
        "        y_true = y_true.contiguous().view(-1)\n",
        "    return y_pred, y_true\n",
        "\n",
        "    \n",
        "########################################################\n",
        "\n",
        "def compute_accuracy(y_pred, y_true, mask_index):\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
        "\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    \n",
        "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
        "    valid_indices = torch.ne(y_true, mask_index).float()\n",
        "    \n",
        "    n_correct = (correct_indices * valid_indices).sum().item()\n",
        "    n_valid = valid_indices.sum().item()\n",
        "\n",
        "    return n_correct / n_valid * 100\n",
        "\n",
        "def sequence_loss(y_pred, y_true, mask_index):\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
        "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)\n",
        "\n",
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbI9b3GTh90x"
      },
      "source": [
        "### 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95S17f2Gh_Yp",
        "outputId": "4025e7bd-3688-49f9-eca5-0885769737b6"
      },
      "source": [
        "## 문자 어휘 사전의 크기에 따라 결정\n",
        "##  = 타임 스텝마다 출력에 나타나는 클래스 개수\n",
        "\n",
        "\n",
        "args = Namespace(\n",
        "    # 날짜와 경로 정보\n",
        "    surname_csv=\"data/surnames/surnames_with_splits.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"model_storage/ch7/model2_conditioned_surname_generation\",\n",
        "    # 모델 하이퍼파라미터\n",
        "    char_embedding_size=32,\n",
        "    rnn_hidden_size=32,\n",
        "    # 훈련 하이퍼파라미터\n",
        "    seed=1337,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=128,\n",
        "    num_epochs=100,\n",
        "    early_stopping_criteria=5,\n",
        "    # 실행 옵션\n",
        "    catch_keyboard_interrupt=True,\n",
        "    cuda=True,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    reload_from_files=False,\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"파일 경로: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "# CUDA 체크\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "    \n",
        "print(\"CUDA 사용 여부: {}\".format(args.cuda))\n",
        "\n",
        "# 재현성을 위해 시드 설정\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# 디렉토리 처리\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일 경로: \n",
            "\tmodel_storage/ch7/model2_conditioned_surname_generation/vectorizer.json\n",
            "\tmodel_storage/ch7/model2_conditioned_surname_generation/model.pth\n",
            "CUDA 사용 여부: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LHhG5KhXTE3"
      },
      "source": [
        "### 7.3.6 모델 훈련과 결과\n",
        "\n",
        "**변경된 사항**\n",
        "1. 3차원 텐서를 2차원 텐서로 변환\n",
        "\n",
        "    3차원 텐서 (배치 차원, 시퀀스, 예측 벡터)\n",
        "2. 가변 길이 시퀀스를 위해 마스킹 인덱스 준비\n",
        "\n",
        "    마스킹된 인덱스에서는 손실 계산 안함\n",
        "\n",
        "\n",
        "**???**\n",
        "1. 예측과 타깃을 손실 함수가 기대하는 크기 (예측은 2차원, 타깃은 1차원)으로 정규화\n",
        "2. 각 행은 하나의 샘플, 즉 시퀀스에 있는 하나의 타임 스텝을 나타냄"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwOYgfKXiRQC",
        "outputId": "60b4418d-e946-4eba-990b-6c4d2bfa75f9"
      },
      "source": [
        "!mkdir data\n",
        "!wget https://git.io/Jqfup -O data/download.py\n",
        "!wget https://git.io/Jqfze -O data/get-all-data.sh\n",
        "!chmod 755 data/get-all-data.sh\n",
        "%cd data\n",
        "!./get-all-data.sh\n",
        "%cd .."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-04 04:21:42--  https://git.io/Jqfup\n",
            "Resolving git.io (git.io)... 54.162.128.250, 18.205.36.100, 54.157.58.70, ...\n",
            "Connecting to git.io (git.io)|54.162.128.250|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_7/7_3_surname_generation/data/download.py [following]\n",
            "--2021-10-04 04:21:43--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_7/7_3_surname_generation/data/download.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1572 (1.5K) [text/plain]\n",
            "Saving to: ‘data/download.py’\n",
            "\n",
            "data/download.py    100%[===================>]   1.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-04 04:21:43 (17.1 MB/s) - ‘data/download.py’ saved [1572/1572]\n",
            "\n",
            "--2021-10-04 04:21:43--  https://git.io/Jqfze\n",
            "Resolving git.io (git.io)... 54.162.128.250, 18.205.36.100, 54.157.58.70, ...\n",
            "Connecting to git.io (git.io)|54.162.128.250|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_7/7_3_surname_generation/data/get-all-data.sh [following]\n",
            "--2021-10-04 04:21:44--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_7/7_3_surname_generation/data/get-all-data.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 507 [text/plain]\n",
            "Saving to: ‘data/get-all-data.sh’\n",
            "\n",
            "data/get-all-data.s 100%[===================>]     507  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-04 04:21:44 (22.6 MB/s) - ‘data/get-all-data.sh’ saved [507/507]\n",
            "\n",
            "/content/data\n",
            "Trying to fetch /content/data/surnames/surnames.csv\n",
            "6it [00:00, 3341.19it/s]\n",
            "Trying to fetch /content/data/surnames/surnames_with_splits.csv\n",
            "8it [00:00, 2938.22it/s]\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thxx3nIZiV72"
      },
      "source": [
        "\n",
        "if args.reload_from_files:\n",
        "    # 체크포인트를 로드합니다.\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv,\n",
        "                                                              args.vectorizer_file)\n",
        "else:\n",
        "    # 데이터셋과 Vectorizer를 만듭니다.\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "\n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "model = SurnameGenerationModel(char_embedding_size=args.char_embedding_size,\n",
        "                               char_vocab_size=len(vectorizer.char_vocab),\n",
        "                               num_nationalities=len(vectorizer.nationality_vocab),\n",
        "                               rnn_hidden_size=args.rnn_hidden_size,\n",
        "                               padding_idx=vectorizer.char_vocab.mask_index,\n",
        "                               dropout_p=0.5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197,
          "referenced_widgets": [
            "30981757c4a74755b7a0beaca32a5aa5",
            "23b7ae4120e144dd85b3324e8aeaf31b",
            "eb8703fe478d41218d5f98a0bb77f2be",
            "90a8eb7a8b934a2d852e91f3f0a18f44",
            "72913cd2c02947ffb61e1b1cfc356fd5",
            "b52ada70cbc6466f9b366969bbc22896",
            "a05ab9d95aaf433e9dab1f56937e982e",
            "8659013f61c0486eb6f6f673addf3e1d",
            "21b2d91c704645249781cf1feeca9028",
            "e22ab6e6f9284e0a9caee14e0e8279dc",
            "c50279e601cb47f7bb5e136394a46535",
            "72ca7cdd0cdd40bda59eb866359e5dfd",
            "cc60040f727b4b3198dcf594a76ea502",
            "8a7ec0e887bb4d558e7facf2c1b72185",
            "ea81744fa6684b539c42adae4b16616e",
            "9464c094ec894c4bb6fe079148b1bc32",
            "328ade7c499c42258e29803976b98068",
            "32762a2ab11644f2bf0430ee8565cf94",
            "ab21f93a2ece42a19001df66223c66c7",
            "dbb7df10405f42749bae31dc5d8de9c2",
            "6f44896095004e3e801402bf8fa4179a",
            "059b431a1209490bbe0ab3d51f41e3c9",
            "c6feadd74341418eabe1835eb0805080",
            "f71dc56d651747c2b0099f58738158ed",
            "54ffc33b1f0d4574bf0ee9ec4e37e37b",
            "838bd663f8ed4c69b4791a466b160791",
            "3cc9a4269bb44a628927baff001f3d10",
            "496ea69275eb4b2baf8fb3991e7fc614",
            "fd293671f5524706abeaab8f33e5b3f4",
            "eef3b330321e4272a1584f4ee275ce52",
            "65d97d6d368d40de9610036db53456b8",
            "ca532a0e757e4523ac939b21bc730d0f",
            "eff18abbe14b4d319290c056381baacb"
          ]
        },
        "id": "171SYr89iWg-",
        "outputId": "093826af-3f9f-4100-de3a-c437586c2092"
      },
      "source": [
        "\n",
        "mask_index = vectorizer.char_vocab.mask_index\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm.notebook.tqdm(desc='training routine', \n",
        "                               total=args.num_epochs,\n",
        "                               position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm.notebook.tqdm(desc='split=train',\n",
        "                               total=dataset.get_num_batches(args.batch_size), \n",
        "                               position=1, \n",
        "                               leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm.notebook.tqdm(desc='split=val',\n",
        "                             total=dataset.get_num_batches(args.batch_size), \n",
        "                             position=1, \n",
        "                             leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # 훈련 세트에 대한 순회\n",
        "\n",
        "        # 훈련 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        model.train()\n",
        "        \n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # 훈련 과정은 5단계로 이루어집니다\n",
        "\n",
        "            # --------------------------------------\n",
        "            # 단계 1. 그레이디언트를 0으로 초기화합니다\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 단계 2. 출력을 계산합니다\n",
        "            y_pred = model(x_in=batch_dict['x_data'], \n",
        "                           nationality_index=batch_dict['class_index'])\n",
        "\n",
        "            # 단계 3. 손실을 계산합니다\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "            # 단계 4. 손실을 사용해 그레이디언트를 계산합니다\n",
        "            loss.backward()\n",
        "\n",
        "            # 단계 5. 옵티마이저로 가중치를 업데이트합니다\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            \n",
        "            # 이동 손실과 이동 정확도를 계산합니다\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # 진행 상태 막대 업데이트\n",
        "            train_bar.set_postfix(loss=running_loss,\n",
        "                                  acc=running_acc,\n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # 검증 세트에 대한 순회\n",
        "\n",
        "        # 검증 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # 단계 1. 출력을 계산합니다\n",
        "            y_pred = model(x_in=batch_dict['x_data'], \n",
        "                           nationality_index=batch_dict['class_index'])\n",
        "\n",
        "            # 단계 2. 손실을 계산합니다\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "            # 단계 3. 이동 손실과 이동 정확도를 계산합니다\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            \n",
        "            # 진행 상태 막대 업데이트\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=model, \n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "            \n",
        "        # 샘플링을 위해 모델을 cpu로 옮깁니다\n",
        "        nationalities = np.random.choice(np.arange(len(vectorizer.nationality_vocab)), replace=True, size=2)\n",
        "        model = model.cpu()\n",
        "        sampled_surnames = decode_samples(\n",
        "            sample_from_model(model, vectorizer, nationalities=nationalities), \n",
        "            vectorizer)\n",
        "        \n",
        "        sample1 = \"{}->{}\".format(vectorizer.nationality_vocab.lookup_index(nationalities[0]), \n",
        "                                  sampled_surnames[0])\n",
        "        sample2 = \"{}->{}\".format(vectorizer.nationality_vocab.lookup_index(nationalities[1]), \n",
        "                                  sampled_surnames[1])\n",
        "        epoch_bar.set_postfix(sample1=sample1, \n",
        "                              sample2=sample2)\n",
        "        # 원래 장치로 모델을 이동합니다\n",
        "        model = model.to(args.device)\n",
        "        \n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "        \n",
        "except KeyboardInterrupt:\n",
        "    print(\"반복 중지\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30981757c4a74755b7a0beaca32a5aa5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72ca7cdd0cdd40bda59eb866359e5dfd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=train:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6feadd74341418eabe1835eb0805080",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=val:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slZoq2ggixnn"
      },
      "source": [
        "# 가장 좋은 모델을 사용해 테스트 세트의 손실과 정확도를 계산합니다\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # 출력을 계산합니다\n",
        "    y_pred = model(x_in=batch_dict['x_data'], \n",
        "                   nationality_index=batch_dict['class_index'])\n",
        "\n",
        "    # 손실을 계산합니다\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "    \n",
        "    # 이동 손실과 이동 정확도를 계산합니다\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1tOl6LFlPWS",
        "outputId": "923302de-7e43-40ea-ec0b-7c080bc683d7"
      },
      "source": [
        "print(\"테스트 손실: {};\".format(train_state['test_loss']))\n",
        "print(\"테스트 정확도: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 손실: 2.4481899340947466;\n",
            "테스트 정확도: 28.328345758553198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r73TDRbDlP1v",
        "outputId": "eb539b4c-c57c-4042-ead0-4ce8dc54850a"
      },
      "source": [
        "model = model.cpu()\n",
        "for index in range(len(vectorizer.nationality_vocab)):\n",
        "    nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
        "    print(\"{} 샘플: \".format(nationality))\n",
        "    sampled_indices = sample_from_model(model, vectorizer,  \n",
        "                                        nationalities=[index] * 3, \n",
        "                                        temperature=0.7)\n",
        "    for sampled_surname in decode_samples(sampled_indices, vectorizer):\n",
        "        print(\"-  \" + sampled_surname)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arabic 샘플: \n",
            "-  Madari\n",
            "-  Shani\n",
            "-  Mashishi\n",
            "Chinese 샘플: \n",
            "-  Yao\n",
            "-  Nal\n",
            "-  Sa\n",
            "Czech 샘플: \n",
            "-  Kini\n",
            "-  Rawinkuwa\n",
            "-  Sharkel\n",
            "Dutch 샘플: \n",
            "-  Agllley\n",
            "-  Sone\n",
            "-  S\n",
            "English 샘플: \n",
            "-  Meranele\n",
            "-  Caltrern\n",
            "-  Ralser\n",
            "French 샘플: \n",
            "-  Tililpe\n",
            "-  Dowlran\n",
            "-  Normad\n",
            "German 샘플: \n",
            "-  Bettden\n",
            "-  Funbes\n",
            "-  Aon\n",
            "Greek 샘플: \n",
            "-  Mujilelei\n",
            "-  Palneitleban\n",
            "-  Sanosokis\n",
            "Irish 샘플: \n",
            "-  U'Choen\n",
            "-  Toryan\n",
            "-  Elliw\n",
            "Italian 샘플: \n",
            "-  Narne\n",
            "-  Alomale\n",
            "-  Pereto\n",
            "Japanese 샘플: \n",
            "-  Skadama\n",
            "-  Kamaaa\n",
            "-  Vasana\n",
            "Korean 샘플: \n",
            "-  Noer\n",
            "-  So\n",
            "-  Van\n",
            "Polish 샘플: \n",
            "-  Mutten\n",
            "-  Randrik\n",
            "-  Hazshen\n",
            "Portuguese 샘플: \n",
            "-  Emannae\n",
            "-  Manwaz\n",
            "-  Moris\n",
            "Russian 샘플: \n",
            "-  Agelensky\n",
            "-  Dunin\n",
            "-  Dutaf\n",
            "Scottish 샘플: \n",
            "-  Niskonlen\n",
            "-  Manks\n",
            "-  Caler\n",
            "Spanish 샘플: \n",
            "-  Cafisars\n",
            "-  Monfi\n",
            "-  Beino\n",
            "Vietnamese 샘플: \n",
            "-  Larry\n",
            "-  Oba\n",
            "-  Zh\n"
          ]
        }
      ]
    }
  ]
}